\vspace{-2mm}
\section{Dataset overview}
\label{sec:dataset}

A major obstacle to progress on melody transcription is the lack of a large volume of data for training. 
To the best of our knowledge, 
there are only two datasets available with annotations suitable for melody transcription: the RWC Music Database~\cite{goto2002rwc,goto2003rwc,goto2004development} (RWC-MDB), 
and a dataset labeled by Laaksonen~\cite{laaksonen2014automatic}. 
The former is larger but the annotations are inconsistent---Ryyn{\"a}nen~and~Klapuri note that only $8.7$ hours ($130$ songs) are usable for melody transcription~\cite{ryynanen2008automatic}, while the latter only contains $1.5$ hours. 

We derive a suitably large dataset for melody transcription using crowdsourced annotations from \hooktheory{}.\footnote{\hooktheory{} annotations are published under a \href{https://creativecommons.org/licenses/by-nc-sa/3.0/}{CC BY-NC-SA 3.0} license, which our dataset inherits.}
\hooktheory{} is a platform where users can easily create and share musical analyses of particular recordings hosted on YouTube, with Wikipedia-style editing. 
The dataset contains annotations for $22$k segments of $13$k unique recordings totaling $50$ hours of labeled audio. 
The audio content covers a wide range of genres---there is a skew towards pop and rock but many other genres are represented including EDM, jazz, and even classical. 
We create an artist-stratified $8$:$1$:$1$ split of the dataset for training, validation, and testing. 
The dataset also includes chord annotations which may facilitate chord recognition research.

While \hooktheory{} data has been used previously for MIR tasks like 
harmonization~\cite{chen2021surprisenet,yeh2021automatic}, 
chord recognition~\cite{jiang2019mirex}, and 
representation learning~\cite{jiang2020transformer}, 
making use of this platform for MIR is currently cumbersome. 
One obstacle is that the annotations are created via a ``functional'' interface, i.e.,~one which uses scale degrees and roman numerals relative to a key signature instead of absolute notes and chord names. 
In contrast, most MIR research favors absolute labels.
Hence, we convert annotations from this functional format to a simple (JSON-based) absolute format. 
One caveat is that the \hooktheory{} annotation interface uses a relative octave system, 
so there is no way to reliably map annotations to a ground truth octave.
Thus, melodies in our dataset also contain only relative octave information, consistent with the octave-invariant evaluation proposed in \Cref{sec:eval}.