\section{Conclusion}

We present a new method and dataset which together improve melody transcription on broad music audio. 
Our method benefits from the rich representations learned by generative models pre-trained on broad audio. 
This suggests that further improvement in melody transcription may be possible without additional melody transcription data, i.e.,~by scaling up or otherwise improving the pre-training procedure. 
By releasing our models and dataset, we hope to spark renewed interest for melody transcription in the MIR community, which in turn may reduce the gap between human perception and machine recognition of a fundamental aspect of music.